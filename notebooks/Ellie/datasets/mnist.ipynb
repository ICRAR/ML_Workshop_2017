{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Provides data for the MNIST dataset.\n",
    "\n",
    "The dataset scripts used to create the dataset can be found at:\n",
    "tensorflow/models/slim/datasets/download_and_convert_mnist.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from datasets import dataset_utils\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "_FILE_PATTERN = 'mnist_%s.tfrecord'\n",
    "\n",
    "_SPLITS_TO_SIZES = {'train': 60000, 'test': 10000}\n",
    "\n",
    "_NUM_CLASSES = 10\n",
    "\n",
    "_ITEMS_TO_DESCRIPTIONS = {\n",
    "    'image': 'A [28 x 28 x 1] grayscale image.',\n",
    "    'label': 'A single integer between 0 and 9',\n",
    "}\n",
    "\n",
    "\n",
    "def get_split(split_name, dataset_dir, file_pattern=None, reader=None):\n",
    "  \"\"\"Gets a dataset tuple with instructions for reading MNIST.\n",
    "\n",
    "  Args:\n",
    "    split_name: A train/test split name.\n",
    "    dataset_dir: The base directory of the dataset sources.\n",
    "    file_pattern: The file pattern to use when matching the dataset sources.\n",
    "      It is assumed that the pattern contains a '%s' string so that the split\n",
    "      name can be inserted.\n",
    "    reader: The TensorFlow reader type.\n",
    "\n",
    "  Returns:\n",
    "    A `Dataset` namedtuple.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: if `split_name` is not a valid train/test split.\n",
    "  \"\"\"\n",
    "  if split_name not in _SPLITS_TO_SIZES:\n",
    "    raise ValueError('split name %s was not recognized.' % split_name)\n",
    "\n",
    "  if not file_pattern:\n",
    "    file_pattern = _FILE_PATTERN\n",
    "  file_pattern = os.path.join(dataset_dir, file_pattern % split_name)\n",
    "\n",
    "  # Allowing None in the signature so that dataset_factory can use the default.\n",
    "  if reader is None:\n",
    "    reader = tf.TFRecordReader\n",
    "\n",
    "  keys_to_features = {\n",
    "      'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "      'image/format': tf.FixedLenFeature((), tf.string, default_value='raw'),\n",
    "      'image/class/label': tf.FixedLenFeature(\n",
    "          [1], tf.int64, default_value=tf.zeros([1], dtype=tf.int64)),\n",
    "  }\n",
    "\n",
    "  items_to_handlers = {\n",
    "      'image': slim.tfexample_decoder.Image(shape=[28, 28, 1], channels=1),\n",
    "      'label': slim.tfexample_decoder.Tensor('image/class/label', shape=[]),\n",
    "  }\n",
    "\n",
    "  decoder = slim.tfexample_decoder.TFExampleDecoder(\n",
    "      keys_to_features, items_to_handlers)\n",
    "\n",
    "  labels_to_names = None\n",
    "  if dataset_utils.has_labels(dataset_dir):\n",
    "    labels_to_names = dataset_utils.read_label_file(dataset_dir)\n",
    "\n",
    "  return slim.dataset.Dataset(\n",
    "      data_sources=file_pattern,\n",
    "      reader=reader,\n",
    "      decoder=decoder,\n",
    "      num_samples=_SPLITS_TO_SIZES[split_name],\n",
    "      num_classes=_NUM_CLASSES,\n",
    "      items_to_descriptions=_ITEMS_TO_DESCRIPTIONS,\n",
    "      labels_to_names=labels_to_names)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
